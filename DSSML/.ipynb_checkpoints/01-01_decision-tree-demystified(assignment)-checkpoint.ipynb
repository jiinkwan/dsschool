{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 의사결정나무(Decision Tree) 구현하기\n",
    "\n",
    "이번 수업에서는 머신러닝 알고리즘 중 하나인 의사결정나무(이하 Decision Tree)에 대해서 알아보고 이를 구현해보겠습니다.\n",
    "\n",
    "Decision Tree는 지도 학습(이하 Supervised Learning)의 한 종류로서, Feature와 Label이 주어지면 이 데이터 사이의 패턴을 예측합니다. 이 과정에서 나오는 결과물을 시각화하면, 그 그림이 마치 나무(Tree)같다고 하여 의사결정나무라는 명칭을 사용하고 있습니다.\n",
    "\n",
    "![Decision Tree](http://engineering.pivotal.io/images/interpreting-decision-trees-and-random-forests/reg_dt_path.png)\n",
    "\n",
    "[scikit-learn](http://scikit-learn.org/)의 의사결정나무([DecisionTreeRegressor](http://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html)를 [graphviz](https://www.graphviz.org/)라는 툴로 시각화한 결과물. 그림이 마치 나무가 가치를 치듯이 뻗어내려간다는 의미에서 의사결정나무라는 표현을 사용합니다.\n",
    "\n",
    "이러한 머신러닝 알고리즘을 잘 이해하는 방법은, 알고리즘을 파이썬과 같은 프로그래밍 언어로 직접 구현해보는 것입니다. 그러므로 이번 시간에는 주어진 데이터와 문제를 Decision Tree를 활용하여 풀되, [scikit-learn](http://scikit-learn.org/)과 같은 패키지를 사용하지 않고 파이썬으로 직접 구현해서 풀어보는 시간을 가질 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 파이썬의 데이터 분석 패키지 판다스(pandas.pydata.org)를 읽어옵니다.\n",
    "# 이 패키지를 pd라는 축약으로 사용합니다.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset\n",
    "\n",
    "먼저 Decision Tree라는 알고리즘의 원리를 잘 이해할 수 있는 데이터셋을 생성해보겠습니다.\n",
    "\n",
    "이번에 다룰 데이터셋은 [인스타그램(Instagram)](https://www.instagram.com/)의 해시태그 데이터입니다. 인스타그램의 포스팅에는 크게 1) 사진, 2) 글, 3) 해시태그, 4) 코멘트, 5) 좋아요(like) 횟수가 있습니다. ([예시](https://www.instagram.com/p/BnML40RH-Wg)) 이 중 좋아요 횟수는 인스타그램 포스팅의 유명세를 나타내는 척도 중 하나입니다.\n",
    "\n",
    "그러므로 이번에는 3) 해시태그와 5) 좋아요(like)의 상관관계를 Decision Tree로 예측해보겠습니다. 수강생은 주어진 인스타그램 포스팅 데이터 중, 해시태그와 좋아요를 바탕으로 어떤 해시태그를 사용하는 사람이 좋아요를 받을지를 예측하는 모델을 만들겠습니다. 먼저 이를 위한 예시 데이터셋을 생성한 뒤, 이 데이터셋을 바탕으로 Decision Tree를 구현해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>패션스타그램</th>\n",
       "      <th>데일리룩</th>\n",
       "      <th>우산</th>\n",
       "      <th>like</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>이름</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kang</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kim</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Choi</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Park</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yoon</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lee</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      패션스타그램   데일리룩     우산   like\n",
       "이름                               \n",
       "Kang   False   True  False   True\n",
       "Kim    False  False  False  False\n",
       "Choi    True  False  False   True\n",
       "Park   False  False  False   True\n",
       "Yoon   False  False  False  False\n",
       "Lee     True  False  False   True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 먼저 데이터를 생성합니다.\n",
    "# 데이터에는 크게 이름, 해시태그(데일리룩, 패션스타그램, 우산), followers 인원 수, 좋아요(like) 여부가 들어가 있습니다.\n",
    "data = {\n",
    "    '이름': [\"Kang\", \"Kim\", \"Choi\", \"Park\", \"Yoon\", \"Lee\"],\n",
    "    '데일리룩': [True, False, False, False, False, False],\n",
    "    '패션스타그램': [False, False, True, False, False, True],\n",
    "    '우산': [False, False, False, False, False, False],\n",
    "    'like': [True, False, True, True, False, True]\n",
    "}\n",
    "\n",
    "# 이 데이터를 Pandas의 DataFrame으로 변환해줍니다.\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# 이후 이 DataFrame에서 이름을 Index로 지정해줍니다.\n",
    "data = data.set_index(\"이름\")\n",
    "\n",
    "# data의 컬럼 순서를 정렬해줍니다. 해시태그가 제일 앞에, 그 다음으로 followers와 like가 오게 합니다.\n",
    "data = data[[\"패션스타그램\", \"데일리룩\", \"우산\", \"like\"]]\n",
    "\n",
    "# .shape로 data의 세로와 가로를 출력합니다.\n",
    "# 세로는 총 6개, 가로는 총 5개, 그러므로 (6, 5)가 나와야 합니다.\n",
    "print(data.shape)\n",
    "\n",
    "# 이 데이터를 출력합니다.\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Decision Tree를 구현하기 전에, 간단한 설정(configuration)을 미리 해두겠습니다. Decision Tree는 Supervised Learning 알고리즘이기 때문에, 크게 다음의 데이터가 필요합니다.\n",
    "\n",
    "* Label - 우리가 맞춰야 하는 정답에 해당합니다. 이번에는 좋아요(like)를 Label로 지정하겠습니다.\n",
    "* Feature - 우리가 정답을 맞추는데 필요한 정보입니다. 인스태그램 해시태그들이 대표적인 예가 되겠죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'like'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label로는 좋아요(like)를 지정합니다.\n",
    "label_name = \"like\"\n",
    "label_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['데일리룩', '우산', '패션스타그램'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위에서 설정한 Label을 제외한 나머지를 feature라고 판단합니다.\n",
    "# 이를 feature_names라는 이름의 변수에 할당합니다.\n",
    "feature_names = data.columns.difference([label_name])\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Decision Tree를 구현하기 전에, 구현에 도움이 되는 몇 가지 기능을 먼저 준비해놓겠습니다. 먼저 1) Decision Tree를 시각화하는 기능, 2) 그리고 Decision Tree를 통해 정답을 예측하는 기능, 이렇게 두 가지를 먼저 구현해놓은 뒤 시작하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Tree\n",
    "\n",
    "먼저 Decision Tree를 시각화하는 기능입니다. 트리를 성공적으로 만들었다면, 다음의 코드를 통해 트리를 시각화해서 육안으로 확인할 수 있습니다.\n",
    "\n",
    "<br />\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "```display_tree(tree)```\n",
    "</div>\n",
    "\n",
    "<br />\n",
    "\n",
    "\n",
    "시각화를 하는데는 [graphviz](https://www.graphviz.org/)라는 기능을 사용합니다. 이를 사용하기 위해서는 Graphviz라는 툴을 설치해야 하는데, Graphviz를 설치하는 방법은 다음과 같습니다.\n",
    "\n",
    "1. 컴퓨터에 아나콘다(Anaconda)로 파이썬을 설치했을 경우 - 1) 컴퓨터에서 아나콘다 네비게이터(Anaconda Navigator)를 실행하면, 2) 좌측에 환경(Environment) 탭이 있습니다. 3) 이 탭에서 'installed'라고 되어있는 콤보 박스를 'not installed'라고 변경한 뒤 4) graphviz로 검색하면 설치가 필요한 graphviz 관련 패키지 리스트들이 나옵니다. 이를 전부 설치하시면 됩니다.\n",
    "\n",
    "1. 컴퓨터에 아나콘다로 파이썬을 설치하지 않은 경우 - 먼저 다음의 링크에서 [Graphviz](http://graphviz.org/download/)를 설치합니다. 이후 쥬피터 노트북에서 !pip install graphviz를 실행하면 Graphviz가 성공적으로 설치될 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# graphviz 패키지를 읽어옵니다.\n",
    "import graphviz\n",
    "\n",
    "# graphviz 패키지에서, 트리 시각화의 가장 기본이 되는 Digraph를 가져옵니다.\n",
    "from graphviz import Digraph\n",
    "\n",
    "# 트리의 각 노드 하나를 시각화하는 함수를 정의합니다.\n",
    "def display_node(dot, key, node):\n",
    "    # node가 잎(leaf)인지 아닌지에 따라 다른 방식으로 시각화해야 합니다.\n",
    "    if node[\"leaf\"] == True:\n",
    "        # node에서 확률(probability)값을 가져옵니다.\n",
    "        probability = node['probability']\n",
    "        \n",
    "        # 확률값을 예쁘게 출력하기 위해, 소숫점을 4자리까지 자릅니다.\n",
    "        probability = round(probability, 4)\n",
    "        \n",
    "        # 소숫점을 자른 뒤, 시각화를 위해 실수형(float)에서 문자열(string)으로 변환합니다.\n",
    "        probability = str(probability)\n",
    "        \n",
    "        # 이를 Digraph 안에 삽입합니다.\n",
    "        dot.node(key, probability)\n",
    "    # 잎(leaf)이 아닐 경우는 다른 방식으로 시각화해야 합니다.\n",
    "    else:\n",
    "        # 구체적으로 어떤 조건으로 가르게 되었는지 설명(description)을 가져옵니다.\n",
    "        description = node['description']\n",
    "        \n",
    "        # 이 설명을 시각화에 집어넣습니다.\n",
    "        dot.node(key, description)\n",
    "        \n",
    "        # 트리의 노드에 좌측 노드가 있으면 이를 시각화합니다.\n",
    "        if \"left\" in node:\n",
    "            # 현재 키에 'L'마크를 뒤에 추가합니다. 이를 좌측 노드라고 가정합니다.\n",
    "            left_key = key + \"L\"\n",
    "            \n",
    "            # 이 좌측 노드를 시각화합니다.\n",
    "            display_node(dot, left_key, node['left'])\n",
    "            \n",
    "            # 좌측 노드를 시각화한 결과를 현재 노드와 연결합니다.\n",
    "            dot.edge(key, left_key)\n",
    "\n",
    "        # 비슷하게 트리의 노드에 우측 노드가 있으면 이를 시각화합니다.\n",
    "        if \"right\" in node:\n",
    "            # 현재 키에 'R'마크를 뒤에 추가합니다. 이를 우측 노드라고 가정합니다.\n",
    "            right_key = key + \"R\"\n",
    "            \n",
    "            # 이 우측 노드를 시각화합니다.\n",
    "            display_node(dot, right_key, node['right'])\n",
    "            \n",
    "            # 우측 노드를 시각화한 결과를 현재 노드와 연결합니다.\n",
    "            dot.edge(key, right_key)\n",
    "\n",
    "# 트리 전체를 시각화하는 함수를 정의합니다.\n",
    "def display_tree(tree):\n",
    "    # 시각화의 기본이 되는 Digraph를 정의합니다.\n",
    "    dot = Digraph(comment='Decision Tree')\n",
    "\n",
    "    # 트리의 맨 위를 노드(node)라고 가정하고 시각화합니다.\n",
    "    display_node(dot, \"Root\", tree)\n",
    "\n",
    "    # 이 결과를 graphviz로 출력합니다.\n",
    "    return graphviz.Source(dot.source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict\n",
    "\n",
    "다음은 트리를 활용해 결과를 예측(predict)하는 함수입니다. 트리를 성공적으로 만들었다면, 여기에 있는 ```predict_tree```라는 함수를 활용하여 결과를 예측할 수 있습니다.\n",
    "\n",
    "<br />\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "```predictions = predict_tree(data, tree)```\n",
    "</div>\n",
    "\n",
    "<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 트리의 노드(node) 하나에서 예측값을 가져오는 함수를 정의합니다.\n",
    "def predict_node(data, node):\n",
    "    # 노드(node)가 잎인지 아닌지에 따라 예측 방식이 달라집니다\n",
    "    if node['leaf'] == True:\n",
    "        # 만일 잎이라면, 해당 잎에서의 확률(probability)을 가져옵니다.\n",
    "        probability = node[\"probability\"]\n",
    "        \n",
    "        # 이 확률을 판다스 DataFrame의 index와 1 on 1 매칭을 합니다. 이를 예측 결과(result)라고 가정합니다.\n",
    "        # 이 결과를 result라는 이름의 변수에 넣습니다.\n",
    "        result = dict(zip(data.index, len(data) * [probability]))\n",
    "    else:\n",
    "        # 잎이 아니라면, 가지를 치는 조건(condition)을 가져옵니다.\n",
    "        condition = node['condition']\n",
    "        \n",
    "        # 이 조건이 참(True)일 경우의 데이터를 가져옵니다. 이를 left_data라는 이름의 변수에 할당합니다.\n",
    "        left_data = data[condition(data)]\n",
    "        \n",
    "        # 현재 노드의 좌측 노드(node)를 가져와, 좌측 노드에 left_data를 집어넣고 예측합니다.\n",
    "        # 이를 left_result라는 변수에 할당합니다.\n",
    "        left_result = predict_node(left_data, node['left'])\n",
    "        \n",
    "        # 이 조건이 거짓(False)일 경우의 데이터를 가져옵니다. 이를 right_data라는 이름의 변수에 할당합니다.\n",
    "        right_data = data[~condition(data)]\n",
    "        \n",
    "        # 현재 노드의 우측 노드(node)를 가져와, 우측 노드에 right_result를 집어넣고 예측합니다.\n",
    "        # 이를 right_result라는 변수에 할당합니다.\n",
    "        right_result = predict_node(right_data, node['right'])    \n",
    "    \n",
    "        # 좌측 노드의 예측 결과와, 우측 노드의 예측 결과를 하나로 합칩니다.\n",
    "        return {**left_result, **right_result}\n",
    "\n",
    "    # 이 결과를 반환합니다.\n",
    "    return result\n",
    "\n",
    "# 트리 전체를 활용해 결과를 예측하는 함수를 만듭니다.\n",
    "def predict_tree(data, tree):\n",
    "    # 트리의 제일 위(root)를 첫 번쨰 노드라고 가정한 뒤, 주어진 데이터(data)를 활용하여 예측합니다.\n",
    "    predictions = predict_node(data, tree)\n",
    "    \n",
    "    # 이를 판다스(Pandas)의 Series로 변환합니다.\n",
    "    predictions = pd.Series(predictions)\n",
    "    \n",
    "    # 이 예측 결과를 반환합니다.\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Implement a Decision Tree\n",
    "\n",
    "사전에 도움이 되는 내용을 미리 구현했다면, 이제부터는 본격적으로 Decision Tree를 구현하겠습니다.\n",
    "\n",
    "Decision Tree의 핵심은 크게 세 가지입니다. 1) Feature를 활용해 조건(condition)을 만드는 것, 2) 만들어진 조건(condition)의 리스트를 가져와, 평가 기준(ex: gini impurity)을 활용해 중요한 조건과 중요하지 않은 조건을 나누는 것, 3) 중요한 조건 위주로 가치를 친 뒤 나무(Tree)로 만드는 것입니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Conditions\n",
    "\n",
    "먼저 조건을 만드는 것 부터 보겠습니다. Decision Tree는 처음 학습을 시작할 때 주어진 feature를 활용해 조건(condition)을 만듭니다. 가령 feature로 키(cm), 몸무게(kg), 성별(gender)을 받았다면,\n",
    "\n",
    "* 성별(gender) == 남자\n",
    "* 성별(gender) == 여자\n",
    "* 키(cm) < 150 cm\n",
    "* 키(cm) < 157 cm\n",
    "* 키(cm) < 163 cm\n",
    "\n",
    "...\n",
    "\n",
    "* 키(cm) < 192 cm\n",
    "* 키(cm) < 200 cm\n",
    "* 몸무게(kg) < 40 kg\n",
    "* 몸무게(kg) < 42 kg\n",
    "* 몸무게(kg) < 48 kg\n",
    "\n",
    "...\n",
    "\n",
    "* 몸무게(kg) < 98 kg\n",
    "* 몸무게(kg) < 103 kg\n",
    "* 몸무게(kg < 108 kg\n",
    "\n",
    "이런 식으로 feature들을 조건(condition)화 하게 됩니다. 그러므로 여기서는 1) 하나의 feature를 하나 이상의 조건으로 만드는 함수(```make_condition```)와 2) 여러 개의 feature를 받으면 모든 feature를 활용해 이론상으로 존재 가능한 모든 조건을 만드는 함수(```make_condition_list```)를 만들어보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Criterion Methods\n",
    "\n",
    "다음으로는 평가 기준(이하 criterion)을 구현하겠습니다. criterion은 주어진 조건들에서 중요한 조건과 중요하지 않은 조건을 구분하는 역할을 합니다. Decision Tree는 criterion을 통해 중요한 조건을 먼저 사용하여 가지를 치고, 중요하지 않은 조건은 나중에 사용하거나 아예 사용하지 않는 쪽으로 유도합니다.\n",
    "\n",
    "이번 시간에는 Decision Tree에 쓰이는 가장 보편적인 criterion인 지니 불순도(이하 Gini Impurity)를 구현해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini Impurity\n",
    "\n",
    "Gini Impurity는 주어진 데이터에서 불순물이 얼마나 섞여있는지를 측정하는 공식입니다. 구체적인 공식은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "{\\displaystyle \\operatorname I_{G}(p) = 1 - (p_{true})^{2} - (p_{false})^{2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 $(p_{true})^{2}$ 는 주어진 결과가 True일 확률, $(p_{false})^{2}$는 주어진 결과가 False일 확률을 나타냅니다. 즉, 1에서 True일 확률의 제곱을 뺀 뒤, 다시 False일 확률의 제곱을 빼면 됩니다.\n",
    "\n",
    "이 공식은 데이터에서 불순물이 섞여있지 않을수록 0에 가까운 숫자가 나오고, 불순물이 섞여있을수록 0.5에 가까운 숫자가 나옵니다. 예를 들어 100개의 데이터 중 True가 100개, False가 0개라면 Gini Impurity의 결과는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "{\\displaystyle \\operatorname I_{G}(p) = 1 - (p_{true})^{2} - (p_{false})^{2}} = 1 - \\big( \\frac{100}{100} \\big)^{2} - \\big( \\frac{0}{100} \\big)^{2} = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "반면 100개의 데이터 중 True가 50개, False가 50개라면 Gini Impurity의 결과는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "{\\displaystyle \\operatorname I_{G}(p) = 1 - (p_{true})^{2} - (p_{false})^{2}} = 1 - \\big( \\frac{50}{100} \\big)^{2} - \\big( \\frac{50}{100} \\big)^{2} = 0.5\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree에서는 주어진 데이터에서 불순도(impurity)가 낮아지도록 가지를 칩니다. 즉, 데이터의 Gini Impurity가 0일수록 좋은 상황이고, 0.5일 수록 좋지 않은 상황이라고 판단하며, Gini Impurity가 0이 될 때 까지 끊임없이 가지를 치고 나무를 키워나갑니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러므로 Gini Impurity 공식을 구현한 뒤, 이 공식을 활용해 Decision Tree를 구현해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Gini Impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Average Gini Impurity\n",
    "\n",
    "이번에는 Gini Impurity를 활용해, 조건(condition)의 평균 Gini Impurity를 구하는 코드를 작성해보겠습니다. 조건마다의 평균 Gini Impurity는 1) 해당 조건의 참일 경우와, 2) 해당 조건이 거짓일 경우의 Gini Impurity를 구해서 이 score의 평균을 내면 됩니다. 이 score가 가장 낮은 조건이 가장 좋은 조건이라고 간주합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the Best Condition\n",
    "\n",
    "조건마다의 평균 Gini Impurity를 구했다면, 남은 건 이를 활용해 가장 좋은 조건을 찾는 것입니다. 주어진 조건의 Gini Impurity를 구한 뒤, 이 Gini Impurity가 가장 낮은 조건을 가장 좋은 조건이라고 판단합니다. 코드는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Tree\n",
    "\n",
    "조건(condition)을 만드는 부분과 Gini Impurity를 계산하는 부분이 만들어졌으면, 남은 건 이를 조합해서 Decision Tree를 구현하는 것만 남았습니다. Decision Tree를 구현하는 순서는 다음과 같습니다.\n",
    "\n",
    "1. 데이터와 feature, label을 가져옵니다.\n",
    "2. 주어진 feature들로 이론상으로 만들 수 있는 모든 조건(condition)을 만듭니다.\n",
    "3. 이 조건마다의 평균 Gini Impurity를 구합니다.\n",
    "4. 평균 Gini Impurity가 가장 낮은 조건을 가장 좋은 조건이라 판단하고, 이 조건으로 가지를 칩니다.\n",
    "5. 2 ~ 4를 끊임없이 반복합니다.\n",
    "6. 더이상 가지를 칠 수 없는 경우를 잎(leaf)이라고 가정하고 가지를 치는 것을 중단합니다.\n",
    "\n",
    "코드는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "Decision Tree가 만들어졌으면, 만들어진 tree를 활용해서 결과를 예측할 수 있습니다. 예측은 ```predict_tree```라는 함수를 통해 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>패션스타그램</th>\n",
       "      <th>데일리룩</th>\n",
       "      <th>우산</th>\n",
       "      <th>followers</th>\n",
       "      <th>like</th>\n",
       "      <th>like(predict)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>이름</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kang</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kim</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Choi</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>80</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Park</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>210</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yoon</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>101</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lee</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>72</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      패션스타그램   데일리룩     우산  followers   like  like(predict)\n",
       "이름                                                         \n",
       "Kang   False   True  False         10   True            1.0\n",
       "Kim    False  False  False         21  False            0.0\n",
       "Choi    True  False  False         80   True            1.0\n",
       "Park   False  False  False        210   True            1.0\n",
       "Yoon   False  False  False        101  False            0.0\n",
       "Lee     True  False  False         72   True            1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 주어진 데이터와 트리로 결과를 예측(predict)합니다.\n",
    "# 이 결과를 predictions 이라는 이름의 변수에 할당합니다.\n",
    "predictions = predict_tree(data, tree)\n",
    "\n",
    "# 현재 데이터셋을 복사(copy)한 뒤 result라는 이름의 변수에 할당합니다.\n",
    "result = data.copy()\n",
    "\n",
    "# 이 result라는 변수에 할당한 DataFrame에 방금 예측할 결과를 새로운 컬럼으로 추가합니다.\n",
    "result[f\"{label_name}(predict)\"] = predictions\n",
    "\n",
    "# result를 화면에 출력합니다.\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b53f202ec5e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgraphviz\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDigraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
